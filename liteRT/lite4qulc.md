# tflite on qualcomm

convert your ONNX model to a TFLite model.
* using the Qualcomm AI Model Efficiency Toolkit (AI Model Conversion) via the AI Hub cloud tool
* using onnx2tf tool

apply post-training quantization as needed (e.g. float16 quantization for GPU, or int8 quantization for NNAPI)

